{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":55945,"status":"ok","timestamp":1691994660899,"user":{"displayName":"hyoin","userId":"02422338919138335184"},"user_tz":-540},"id":"VjloTULti-rB","outputId":"968fdc80-1a21-4775-c24a-3c94eba0bf58"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n","--2023-08-14 06:30:40--  https://github.com/ninja-build/ninja/releases/download/v1.8.2/ninja-linux.zip\n","Resolving github.com (github.com)... 140.82.121.4\n","Connecting to github.com (github.com)|140.82.121.4|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/1335132/d2f252e2-9801-11e7-9fbf-bc7b4e4b5c83?X-Amz-Algorithm=AWS4-HMAC-SHA256\u0026X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230814%2Fus-east-1%2Fs3%2Faws4_request\u0026X-Amz-Date=20230814T063040Z\u0026X-Amz-Expires=300\u0026X-Amz-Signature=317fe93c5875dd47d2fd319c9e3d74170271d6fe130a33b6ec693f7ee931f424\u0026X-Amz-SignedHeaders=host\u0026actor_id=0\u0026key_id=0\u0026repo_id=1335132\u0026response-content-disposition=attachment%3B%20filename%3Dninja-linux.zip\u0026response-content-type=application%2Foctet-stream [following]\n","--2023-08-14 06:30:40--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/1335132/d2f252e2-9801-11e7-9fbf-bc7b4e4b5c83?X-Amz-Algorithm=AWS4-HMAC-SHA256\u0026X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230814%2Fus-east-1%2Fs3%2Faws4_request\u0026X-Amz-Date=20230814T063040Z\u0026X-Amz-Expires=300\u0026X-Amz-Signature=317fe93c5875dd47d2fd319c9e3d74170271d6fe130a33b6ec693f7ee931f424\u0026X-Amz-SignedHeaders=host\u0026actor_id=0\u0026key_id=0\u0026repo_id=1335132\u0026response-content-disposition=attachment%3B%20filename%3Dninja-linux.zip\u0026response-content-type=application%2Foctet-stream\n","Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.108.133, ...\n","Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.111.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 77854 (76K) [application/octet-stream]\n","Saving to: ‘ninja-linux.zip’\n","\n","ninja-linux.zip     100%[===================\u003e]  76.03K  --.-KB/s    in 0.006s  \n","\n","2023-08-14 06:30:40 (13.2 MB/s) - ‘ninja-linux.zip’ saved [77854/77854]\n","\n","Archive:  ninja-linux.zip\n","  inflating: /usr/local/bin/ninja    \n","update-alternatives: using /usr/local/bin/ninja to provide /usr/bin/ninja (ninja) in auto mode\n","Collecting ftfy\n","  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (2023.6.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.0)\n","Requirement already satisfied: wcwidth\u003e=0.2.5 in /usr/local/lib/python3.10/dist-packages (from ftfy) (0.2.6)\n","Installing collected packages: ftfy\n","Successfully installed ftfy-6.1.1\n","Collecting git+https://github.com/openai/CLIP.git\n","  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-p_4gtp0l\n","  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-req-build-p_4gtp0l\n","  Resolved https://github.com/openai/CLIP.git to commit a1d071733d7111c9c014f024669f959182114e33\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: ftfy in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (6.1.1)\n","Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (2023.6.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (4.66.0)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (2.0.1+cu118)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (0.15.2+cu118)\n","Requirement already satisfied: wcwidth\u003e=0.2.5 in /usr/local/lib/python3.10/dist-packages (from ftfy-\u003eclip==1.0) (0.2.6)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch-\u003eclip==1.0) (3.12.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch-\u003eclip==1.0) (4.7.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch-\u003eclip==1.0) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch-\u003eclip==1.0) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-\u003eclip==1.0) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch-\u003eclip==1.0) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0-\u003etorch-\u003eclip==1.0) (3.27.1)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0-\u003etorch-\u003eclip==1.0) (16.0.6)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision-\u003eclip==1.0) (1.23.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision-\u003eclip==1.0) (2.31.0)\n","Requirement already satisfied: pillow!=8.3.*,\u003e=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision-\u003eclip==1.0) (9.4.0)\n","Requirement already satisfied: MarkupSafe\u003e=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2-\u003etorch-\u003eclip==1.0) (2.1.3)\n","Requirement already satisfied: charset-normalizer\u003c4,\u003e=2 in /usr/local/lib/python3.10/dist-packages (from requests-\u003etorchvision-\u003eclip==1.0) (3.2.0)\n","Requirement already satisfied: idna\u003c4,\u003e=2.5 in /usr/local/lib/python3.10/dist-packages (from requests-\u003etorchvision-\u003eclip==1.0) (3.4)\n","Requirement already satisfied: urllib3\u003c3,\u003e=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests-\u003etorchvision-\u003eclip==1.0) (2.0.4)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests-\u003etorchvision-\u003eclip==1.0) (2023.7.22)\n","Requirement already satisfied: mpmath\u003e=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy-\u003etorch-\u003eclip==1.0) (1.3.0)\n","Building wheels for collected packages: clip\n","  Building wheel for clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for clip: filename=clip-1.0-py3-none-any.whl size=1369499 sha256=b80554b8c0373bb1205644b1c428383ced08d742031e8f2f82573d152c6e9461\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-__x_t9y1/wheels/da/2b/4c/d6691fa9597aac8bb85d2ac13b112deb897d5b50f5ad9a37e4\n","Successfully built clip\n","Installing collected packages: clip\n","Successfully installed clip-1.0\n"]}],"source":["import os\n","\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","\n","import sys\n","from google.colab import drive\n","drive.mount('/content/drive')\n","sys.path.append('/content/drive/MyDrive/drug')\n","\n","pretrained_model_dir = os.path.join(\"/content/drive/MyDrive/drug\", \"models\")\n","os.makedirs(pretrained_model_dir, exist_ok=True)\n","\n","restyle_dir = os.path.join(\"/content/drive/MyDrive/drug\", \"restyle\")\n","stylegan_ada_dir = os.path.join(\"/content/drive/MyDrive/drug\", \"stylegan_ada\")\n","stylegan_nada_dir = os.path.join(\"/content/drive/MyDrive/drug\", \"stylegan_nada\")\n","\n","output_dir = os.path.join(\"/content\", \"output\")\n","\n","output_model_dir = os.path.join(output_dir, \"models\")\n","output_image_dir = os.path.join(output_dir, \"images\")\n","\n","download_with_pydrive = True #@param {type:\"boolean\"}\n","\n","class Downloader(object):\n","    def __init__(self, use_pydrive):\n","        self.use_pydrive = use_pydrive\n","\n","        if self.use_pydrive:\n","            self.authenticate()\n","\n","    def authenticate(self):\n","        auth.authenticate_user()\n","        gauth = GoogleAuth()\n","        gauth.credentials = GoogleCredentials.get_application_default()\n","        self.drive = GoogleDrive(gauth)\n","\n","    def download_file(self, file_id, file_dst):\n","        if self.use_pydrive:\n","            downloaded = self.drive.CreateFile({'id':file_id})\n","            downloaded.FetchMetadata(fetch_all=True)\n","            downloaded.GetContentFile(file_dst)\n","        else:\n","            !gdown --id $file_id -O $file_dst\n","\n","downloader = Downloader(download_with_pydrive)\n","\n","# 이건 해야하나??\n","source_model_type = 'ffhq' #@param['ffhq', 'cat', 'dog', 'church', 'horse', 'car']\n","\n","source_model_download_path = {\"ffhq\":   \"1EM87UquaoQmk17Q8d5kYIAHqu0dkYqdT\",\n","                              \"cat\":    \"https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada/pretrained/afhqcat.pkl\",\n","                              \"dog\":    \"https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada/pretrained/afhqdog.pkl\",\n","                              \"church\": \"1iDo5cUgbwsJEt2uwfgDy_iPlaT-lLZmi\",\n","                              \"car\":    \"1i-39ztut-VdUVUiFuUrwdsItR--HF81w\",\n","                              \"horse\":  \"1irwWI291DolZhnQeW-ZyNWqZBjlWyJUn\"}\n","\n","model_names = {\"ffhq\":   \"ffhq.pt\",\n","               \"cat\":    \"afhqcat.pkl\",\n","               \"dog\":    \"afhqdog.pkl\",\n","               \"church\": \"stylegan2-church-config-f.pkl\",\n","               \"car\":    \"stylegan2-car-config-f.pkl\",\n","               \"horse\":  \"stylegan2-horse-config-f.pkl\"}\n","\n","download_string = source_model_download_path[source_model_type]\n","file_name = model_names[source_model_type]\n","pt_file_name = file_name.split(\".\")[0] + \".pt\"\n","\n","dataset_sizes = {\n","    \"ffhq\":   1024,\n","    \"cat\":    512,\n","    \"dog\":    512,\n","    \"church\": 256,\n","    \"horse\":  256,\n","    \"car\":    512,\n","}\n","\n","if not os.path.isfile(os.path.join(pretrained_model_dir, file_name)):\n","    print(\"Downloading chosen model...\")\n","\n","    if download_string.endswith(\".pkl\"):\n","        !wget $download_string -O $pretrained_model_dir/$file_name\n","    else:\n","        downloader.download_file(download_string, os.path.join(pretrained_model_dir, file_name))\n","\n","if not os.path.isfile(os.path.join(pretrained_model_dir, pt_file_name)):\n","    print(\"Converting sg2 model. This may take a few minutes...\")\n","\n","    tf_path = next(filter(lambda x: \"tensorflow\" in x, sys.path), None)\n","    py_path = tf_path + f\":{stylegan_nada_dir}/ZSSGAN\"\n","    convert_script = os.path.join(stylegan_nada_dir, \"convert_weight.py\")\n","    !PYTHONPATH=$py_path python $convert_script --repo $stylegan_ada_dir --gen $pretrained_model_dir/$file_name\n","!wget https://github.com/ninja-build/ninja/releases/download/v1.8.2/ninja-linux.zip\n","!sudo unzip ninja-linux.zip -d /usr/local/bin/\n","!sudo update-alternatives --install /usr/bin/ninja ninja /usr/local/bin/ninja 1 --force\n","\n","!pip install ftfy regex tqdm\n","!pip install git+https://github.com/openai/CLIP.git\n","\n","from argparse import Namespace\n","\n","import sys\n","import numpy as np\n","\n","from PIL import Image\n","\n","import torch\n","import torchvision.transforms as transforms\n","\n","sys.path.append(restyle_dir)\n","sys.path.append(stylegan_nada_dir)\n","sys.path.append(os.path.join(stylegan_nada_dir, \"ZSSGAN\"))\n","\n","device = 'cuda'\n","\n","%load_ext autoreload\n","%autoreload 2"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":108885,"status":"ok","timestamp":1691994769778,"user":{"displayName":"hyoin","userId":"02422338919138335184"},"user_tz":-540},"id":"DuUrB1S4jH9R"},"outputs":[],"source":["from restyle.utils.common import tensor2im\n","# from restyle.models.psp import pSp\n","from restyle.models.e4e import e4e\n","\n","# # downloader.download_file(\"1sw6I2lRIB0MpuJkpc8F5BJiSZrc0hjfE\", os.path.join(pretrained_model_dir, \"restyle_psp_ffhq_encode.pt\"))\n","# downloader.download_file(\"1e2oXVeBPXMQoUoC_4TNwAWpOPpSEhE_e\", os.path.join(pretrained_model_dir, \"restyle_e4e_ffhq_encode.pt\"))"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30281,"status":"ok","timestamp":1691994800050,"user":{"displayName":"hyoin","userId":"02422338919138335184"},"user_tz":-540},"id":"bO_6-y0_kp6r","outputId":"8f80dc59-29e3-4243-c5d0-e82807e5f90c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Loading ReStyle e4e from checkpoint: /content/drive/MyDrive/drug/models/restyle_e4e_ffhq_encode.pt\n","Model successfully loaded!\n"]}],"source":["encoder_type = 'e4e' #@param['psp', 'e4e']\n","\n","restyle_experiment_args = {\n","    \"model_path\": os.path.join(pretrained_model_dir, f\"restyle_{encoder_type}_ffhq_encode.pt\"),\n","    \"transform\": transforms.Compose([\n","        transforms.Resize((256, 256)),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])])\n","}\n","\n","model_path = restyle_experiment_args['model_path']\n","ckpt = torch.load(model_path, map_location='cpu')\n","\n","opts = ckpt['opts']\n","\n","opts['checkpoint_path'] = model_path\n","opts = Namespace(**opts)\n","\n","restyle_net = (pSp if encoder_type == 'psp' else e4e)(opts)\n","\n","restyle_net.eval()\n","restyle_net.cuda()\n","print('Model successfully loaded!')"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":529,"status":"ok","timestamp":1691994800577,"user":{"displayName":"hyoin","userId":"02422338919138335184"},"user_tz":-540},"id":"ADOHRPkjkudW"},"outputs":[],"source":["def run_alignment(image_path):\n","    import dlib\n","    from scripts.align_faces_parallel import align_face\n","    if not os.path.exists(\"shape_predictor_68_face_landmarks.dat\"):\n","        print('Downloading files for aligning face image...')\n","        os.system('wget http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2')\n","        os.system('bzip2 -dk shape_predictor_68_face_landmarks.dat.bz2')\n","        print('Done.')\n","    predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n","    aligned_image = align_face(filepath=image_path, predictor=predictor)\n","    print(\"Aligned image has shape: {}\".format(aligned_image.size))\n","    return aligned_image\n","\n","def get_avg_image(net):\n","    avg_image = net(net.latent_avg.unsqueeze(0),\n","                    input_code=True,\n","                    randomize_noise=False,\n","                    return_latents=False,\n","                    average_code=True)[0]\n","    avg_image = avg_image.to('cuda').float().detach()\n","    return avg_image\n","\n","opts.n_iters_per_batch = 5\n","opts.resize_outputs = False  # generate outputs at full resolution\n","\n","from restyle.utils.inference_utils import run_on_batch\n"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":122934,"status":"ok","timestamp":1691994923510,"user":{"displayName":"hyoin","userId":"02422338919138335184"},"user_tz":-540},"id":"9nsLjIAcy-pj"},"outputs":[],"source":["# from ZSSGAN.model.ZSSGAN import SG3Generator\n","# # from ZSSGAN.model.ZSSGAN import ZSSGAN\n","# net = SG3Generator('/content/drive/MyDrive/drug/output/Photo_Zombie.pkl')\n","\n","import pickle\n","with open('/content/drive/MyDrive/drug/output/Zombie777.pkl', 'rb') as f:\n","    net = pickle.load(f)['G_ema'].cuda()  # torch.nn.Module\n"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":1068,"status":"ok","timestamp":1691994924568,"user":{"displayName":"hyoin","userId":"02422338919138335184"},"user_tz":-540},"id":"ADvofi-4lM62"},"outputs":[],"source":["from ZSSGAN.utils.file_utils import save_images, get_dir_img_list\n","output_dir = os.path.join(\"/content/drive/MyDrive/drug/\", \"output\")\n","sample_dir = os.path.join(output_dir, \"sample\")\n","\n","def predict(image_path):\n","  original_image = Image.open(image_path).convert(\"RGB\")\n","\n","  input_image = run_alignment(image_path)\n","  print(input_image)\n","\n","  display(input_image)\n","\n","  img_transforms = restyle_experiment_args['transform']\n","  transformed_image = img_transforms(input_image)\n","  print(\"transformed_image\")\n","  # print(transformed_image)\n","\n","  with torch.no_grad():\n","    avg_image = get_avg_image(restyle_net)\n","    result_batch, result_latents = run_on_batch(transformed_image.unsqueeze(0).cuda(), restyle_net, opts, avg_image)\n","\n","\n","  #@title Convert inverted image.\n","  inverted_latent = torch.Tensor(result_latents[0][4]).cuda().unsqueeze(0).unsqueeze(1)\n","\n","  with torch.no_grad():\n","      net.eval()\n","\n","      [sampled_src, sampled_dst] = net(inverted_latent, input_is_latent=True)[0]\n","      print(\"sampled_dst\")\n","      # print(sampled_dst)\n","\n","      # joined_img = torch.cat([sampled_src, sampled_dst], dim=0)\n","      save_images(sampled_dst, sample_dir, \"joined\", 2, 0)\n","      # display(Image.open(os.path.join(sample_dir, f\"joined_{str(0).zfill(6)}.jpg\")).resize((512, 256)))\n","      # Image.open(os.path.join(sample_dir, f\"joined_{str(0).zfill(6)}.jpg\")).resize((512, 256))\n","\n","      image1 = Image.open(os.path.join(sample_dir, f\"joined_{str(0).zfill(6)}.jpg\")).resize((512, 256))\n","      # display(image1)\n","\n","      image2 = input_image\n","      # display(image2)\n","      image1 = image1.resize((256, 256))\n","      image2 = image2.resize((256, 256))\n","      image1_size = image1.size\n","      image2_size = image2.size\n","      new_image = Image.new('RGB',(2*image1_size[0], image1_size[1]), (250,250,250))\n","      new_image.paste(image2,(0,0))\n","      new_image.paste(image1,(image2_size[0],0))\n","      new_image.save('/content/drive/MyDrive/drug/output/sample/merged_image.jpg',\"JPEG\")\n","      # new_image.show()\n","      display(new_image)\n","\n","      return os.path.join(sample_dir, f\"merged_image.jpg\")"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22535,"status":"ok","timestamp":1691994947102,"user":{"displayName":"hyoin","userId":"02422338919138335184"},"user_tz":-540},"id":"-vQaIHabuIt9","outputId":"dd9f8fdb-2a4b-4cb9-e156-60ad00b51f02"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting flask-ngrok\n","  Downloading flask_ngrok-0.0.25-py3-none-any.whl (3.1 kB)\n","Requirement already satisfied: Flask\u003e=0.8 in /usr/local/lib/python3.10/dist-packages (from flask-ngrok) (2.2.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from flask-ngrok) (2.31.0)\n","Requirement already satisfied: Werkzeug\u003e=2.2.2 in /usr/local/lib/python3.10/dist-packages (from Flask\u003e=0.8-\u003eflask-ngrok) (2.3.6)\n","Requirement already satisfied: Jinja2\u003e=3.0 in /usr/local/lib/python3.10/dist-packages (from Flask\u003e=0.8-\u003eflask-ngrok) (3.1.2)\n","Requirement already satisfied: itsdangerous\u003e=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask\u003e=0.8-\u003eflask-ngrok) (2.1.2)\n","Requirement already satisfied: click\u003e=8.0 in /usr/local/lib/python3.10/dist-packages (from Flask\u003e=0.8-\u003eflask-ngrok) (8.1.6)\n","Requirement already satisfied: charset-normalizer\u003c4,\u003e=2 in /usr/local/lib/python3.10/dist-packages (from requests-\u003eflask-ngrok) (3.2.0)\n","Requirement already satisfied: idna\u003c4,\u003e=2.5 in /usr/local/lib/python3.10/dist-packages (from requests-\u003eflask-ngrok) (3.4)\n","Requirement already satisfied: urllib3\u003c3,\u003e=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests-\u003eflask-ngrok) (2.0.4)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests-\u003eflask-ngrok) (2023.7.22)\n","Requirement already satisfied: MarkupSafe\u003e=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2\u003e=3.0-\u003eFlask\u003e=0.8-\u003eflask-ngrok) (2.1.3)\n","Installing collected packages: flask-ngrok\n","Successfully installed flask-ngrok-0.0.25\n","Collecting pyngrok==4.1.1\n","  Downloading pyngrok-4.1.1.tar.gz (18 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from pyngrok==4.1.1) (0.18.3)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyngrok==4.1.1) (6.0.1)\n","Building wheels for collected packages: pyngrok\n","  Building wheel for pyngrok (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyngrok: filename=pyngrok-4.1.1-py3-none-any.whl size=15964 sha256=1782ef95d9d4428939619b13e468c92142761f246132c98c86e78bcd9b17b050\n","  Stored in directory: /root/.cache/pip/wheels/4c/7c/4c/632fba2ea8e88d8890102eb07bc922e1ca8fa14db5902c91a8\n","Successfully built pyngrok\n","Installing collected packages: pyngrok\n","Successfully installed pyngrok-4.1.1\n","Authtoken saved to configuration file: /root/.ngrok2/ngrok.yml\n","Collecting ffmpeg-python\n","  Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n","Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from ffmpeg-python) (0.18.3)\n","Installing collected packages: ffmpeg-python\n","Successfully installed ffmpeg-python-0.2.0\n","Collecting flask_cors\n","  Downloading Flask_Cors-4.0.0-py2.py3-none-any.whl (14 kB)\n","Requirement already satisfied: Flask\u003e=0.9 in /usr/local/lib/python3.10/dist-packages (from flask_cors) (2.2.5)\n","Requirement already satisfied: Werkzeug\u003e=2.2.2 in /usr/local/lib/python3.10/dist-packages (from Flask\u003e=0.9-\u003eflask_cors) (2.3.6)\n","Requirement already satisfied: Jinja2\u003e=3.0 in /usr/local/lib/python3.10/dist-packages (from Flask\u003e=0.9-\u003eflask_cors) (3.1.2)\n","Requirement already satisfied: itsdangerous\u003e=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask\u003e=0.9-\u003eflask_cors) (2.1.2)\n","Requirement already satisfied: click\u003e=8.0 in /usr/local/lib/python3.10/dist-packages (from Flask\u003e=0.9-\u003eflask_cors) (8.1.6)\n","Requirement already satisfied: MarkupSafe\u003e=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2\u003e=3.0-\u003eFlask\u003e=0.9-\u003eflask_cors) (2.1.3)\n","Installing collected packages: flask_cors\n","Successfully installed flask_cors-4.0.0\n"]}],"source":["from flask import Flask, request,jsonify\n","from werkzeug.utils import secure_filename\n","from flask import send_file\n","import os\n","import sys\n","\n","!pip install flask-ngrok\n","!pip install pyngrok==4.1.1\n","!ngrok authtoken '294dzGF6SRGFWn5l0brOtz37HvR_2WRzjVis8V5QuYW9A7Gda'\n","!pip install ffmpeg-python\n","from flask_ngrok import run_with_ngrok\n","!pip install flask_cors\n","from flask_cors import CORS"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1KNAe8iTgW4gAIntSa3OPVYrZRdQt6Tsv"},"id":"HRYE-wrhlVBB","outputId":"66e81b05-ffbc-459a-abc2-c1375d969141"},"outputs":[],"source":["# flask\n","def remo_credir():\n","    try:\n","        import shutil\n","        shutil.rmtree('uploaded/image')\n","        print()\n","    except:\n","        pass\n","\n","    try:\n","        os.mkdir('uploaded/image')\n","    except:\n","        pass\n","\n","app = Flask(__name__)\n","run_with_ngrok(app)\n","CORS(app)\n","\n","app.config['JSON_AS_ASCII'] = False # jsonify에서 한글사용\n","app.config['UPLOAD_FOLDER'] = 'upload' #경로설정\n","\n","@app.route('/AI', methods=['POST','GET'])\n","def pred():\n","    if request.method == 'POST':\n","      remo_credir()\n","      # 입력받은 사용자 사진 저장\n","      f = request.files['file']\n","      print(f)\n","      f.save(os.path.join('/content/drive/MyDrive/drug/upload/', secure_filename(f.filename)))\n","\n","        # GAN 적용\n","\n","        # 입력받은 사용자 사진 삭제\n","\n","        # 결과 이미지 반환\n","          # image_path = \"/content/drive/MyDrive/drug/ML/content/suzy.png\" #@param {'type': 'string'}\n","      image_path = '/content/drive/MyDrive/drug/upload/' + f.filename\n","      result_path=predict(image_path)\n","      return send_file(result_path)\n","    if request.method == 'GET':\n","      return \"get!\"\n","\n","@app.route('/test')\n","def test():\n","  return \"test\"\n","\n","\n","if __name__ == '__main__':\n","    app.run()"]}],"metadata":{"accelerator":"GPU","colab":{"name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}